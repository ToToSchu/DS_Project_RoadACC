{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Note:\n",
    "\n",
    "To run this script you need to install the python library <b>*chardet*</b> (type *pip install chardet* in your terminal)\n",
    "\n",
    "*chardet* helps to detect encodings of files.\n",
    "\n",
    "This notebook is a condensed version of an exploratory notebook where a lot of code cells with test prints have been removed.\n",
    "\n",
    "93 CSV files were downloaded from\n",
    "https://www.data.gouv.fr/en/datasets/bases-de-donnees-annuelles-des-accidents-corporels-de-la-circulation-routiere-annees-de-2005-a-2023/\n",
    "\n",
    "(date of statement 27.03.2025)\n",
    "\n",
    "After an initial exploration of the data files and reading the documentation, I decided to use:\n",
    "\n",
    "The Etalab database on bodily injury road accidents for a given year is divided into four categories, each represented as a separate CSV file:\n",
    "\n",
    "1. CARACTÉRISTIQUES – Describes the general circumstances of the accident.\n",
    "\n",
    "2. LIEUX – Describes the main location of the accident, even if it occurred at an intersection.\n",
    "\n",
    "3. VÉHICULES – Lists the vehicles involved in the accident.\n",
    "\n",
    "4. USAGERS – Describes the road users involved in the accident.\n",
    "\n",
    "The database seems to have the highest level of detail.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Goal of this notebook\n",
    "The goal is to create vertical stacked Dataframes by merging csv-files based on the categories mentioned above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Loading All Relevant CSV Files and Converting Them into DataFrames\n",
    "\n",
    "Here is a list of problems I encountered during initial test runs:\n",
    "\n",
    "- Some CSV files are encoded differently \n",
    "  the package chardet is able to identify encodings, but may not work in all cases.\n",
    "\n",
    "- Some CSV files have different separators (I tried pd.read_csv(\"file.csv\", sep=None, engine=\"python\"), but it didn’t work).\n",
    "\n",
    "- Some CSV files have inconsistent file names.\n",
    "\n",
    "- Some CSV files are not needed (at least for now).\n",
    "\n",
    "The code below is \"solving\" the mentioned problems and creates DataFrames that are stored in a dictionary with the filename as the key for further analysis.\n",
    "\n",
    "I implemented try and except blocks to handle exceptions in the code. What is this? These are errors that can occur during the execution of a program/cell. These errors can be things like division by zero, file not found, encoding problems, etc. \n",
    "Instead of letting the program crash when an error occurs, you use those errors to provoke iterations. This allows you to anticipate errors and define how the program should respond when they happen.\n",
    "\n",
    "<b>One more important note: Make sure to modify folder_path to your environment.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chardet\n",
    "from collections import Counter\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files not chosen for now: []\n",
      "Successfully loaded vehicules-2017.csv (Category: v) with encoding 'ascii'\n",
      "Successfully loaded vehicules-2018.csv (Category: v) with encoding 'ascii'\n",
      "Successfully loaded vehicules-2019.csv (Category: v) with encoding 'utf-8'\n",
      "Successfully loaded vehicules-2020.csv (Category: v) with encoding 'utf-8'\n",
      "Successfully loaded vehicules-2021.csv (Category: v) with encoding 'utf-8'\n",
      "Successfully loaded vehicules-2022.csv (Category: v) with encoding 'utf-8'\n",
      "Successfully loaded vehicules-2023.csv (Category: v) with encoding 'utf-8'\n",
      "Successfully loaded vehicules_2015.csv (Category: v) with encoding 'ascii'\n",
      "Successfully loaded vehicules_2016.csv (Category: v) with encoding 'ascii'\n",
      "Successfully loaded usagers-2017.csv (Category: u) with encoding 'ascii'\n",
      "Successfully loaded usagers-2018.csv (Category: u) with encoding 'ascii'\n",
      "Successfully loaded usagers-2019.csv (Category: u) with encoding 'utf-8'\n",
      "Successfully loaded usagers-2020.csv (Category: u) with encoding 'utf-8'\n",
      "Successfully loaded usagers-2021.csv (Category: u) with encoding 'utf-8'\n",
      "Successfully loaded usagers-2022.csv (Category: u) with encoding 'utf-8'\n",
      "Successfully loaded usagers-2023.csv (Category: u) with encoding 'utf-8'\n",
      "Successfully loaded usagers_2015.csv (Category: u) with encoding 'ascii'\n",
      "Successfully loaded usagers_2016.csv (Category: u) with encoding 'ascii'\n",
      "Successfully loaded lieux-2017.csv (Category: l) with encoding 'ascii'\n",
      "Successfully loaded lieux-2018.csv (Category: l) with encoding 'ascii'\n",
      "Successfully loaded lieux-2019.csv (Category: l) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded lieux-2020.csv (Category: l) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded lieux-2021.csv (Category: l) with encoding 'ISO-8859-1'\n",
      "Successfully loaded lieux-2022.csv (Category: l) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded lieux-2023.csv (Category: l) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded lieux_2015.csv (Category: l) with encoding 'ascii'\n",
      "Successfully loaded lieux_2016.csv (Category: l) with encoding 'ascii'\n",
      "Successfully loaded caract-2023.csv (Category: c) with encoding 'utf-8'\n",
      "Successfully loaded caracteristiques-2017.csv (Category: c) with encoding 'ISO-8859-1'\n",
      "Successfully loaded caracteristiques-2018.csv (Category: c) with encoding 'ISO-8859-1'\n",
      "Successfully loaded caracteristiques-2019.csv (Category: c) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded caracteristiques-2020.csv (Category: c) with encoding 'latin1' and separator ';'\n",
      "Successfully loaded caracteristiques_2015.csv (Category: c) with encoding 'ISO-8859-1'\n",
      "Successfully loaded caracteristiques_2016.csv (Category: c) with encoding 'ISO-8859-1'\n",
      "Successfully loaded carcteristiques-2021.csv (Category: c) with encoding 'utf-8'\n",
      "Successfully loaded carcteristiques-2022.csv (Category: c) with encoding 'latin1' and separator ';'\n"
     ]
    }
   ],
   "source": [
    "# Define the folder path where the CSV files are stored\n",
    "folder_path = r\"C:\\DS_Project_RoadAcc\\raw_data_2015-2023\"\n",
    "\n",
    "# Get a list of all CSV files in the folder\n",
    "csv_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "# Dictionary to store categorized data\n",
    "dataframes = {\n",
    "    \"v\": {},  # Vehicles\n",
    "    \"u\": {},  # Usagers (Users)\n",
    "    \"l\": {},  # Lieux (Locations)\n",
    "    \"c\": {},  # Caracteristiques (Characteristics)\n",
    "    \"y\": {},\n",
    "    \"not_chosen\": {}  # Files that don’t match any category\n",
    "}\n",
    "\n",
    "# Categorize files directly in the dictionary\n",
    "for file in csv_files:\n",
    "    if \"hicules\" in file:\n",
    "        category = \"v\"\n",
    "    elif \"usager\" in file:\n",
    "        category = \"u\"\n",
    "    elif \"lieu\" in file:\n",
    "        category = \"l\"\n",
    "    elif \"istiques\" in file or \"act\" in file:\n",
    "        category = \"c\"\n",
    "    elif \"donn\" not in file and \"9617e399bb6b\" not in file and \"07a3338614\" not in file:\n",
    "        category = \"y\"\n",
    "    else:\n",
    "        category = \"not_chosen\"\n",
    "\n",
    "    # Store an empty dictionary for now (dataframes will be added later)\n",
    "    dataframes[category][file] = None\n",
    "\n",
    "# Print files that were not categorized\n",
    "print(\"Files not chosen for now:\", list(dataframes[\"not_chosen\"].keys()))\n",
    "\n",
    "# List of common encodings and separators\n",
    "common_encodings = ['latin1', 'utf-8', 'utf-8-sig', 'utf-16', 'ISO-8859-1', 'ISO-8859-2', 'ascii']\n",
    "common_separators = [',', ';', '\\t', '|', ':']\n",
    "\n",
    "# Load CSV files into the dictionary, **excluding \"not_chosen\" category**\n",
    "for category_name, files in dataframes.items():\n",
    "    if category_name == \"not_chosen\":  \n",
    "        continue  # Skip \"not_chosen\" category\n",
    "\n",
    "    for file in files.keys():\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        success = False  # Track whether the file was loaded successfully\n",
    "\n",
    "        # Detect encoding with chardet\n",
    "        with open(file_path, 'rb') as f:\n",
    "            result = chardet.detect(f.read(1000))\n",
    "        detected_encoding = result['encoding']\n",
    "\n",
    "        # Try reading with detected encoding\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=detected_encoding, sep=None, engine='python')\n",
    "            dataframes[category_name][file] = df\n",
    "            print(f\"Successfully loaded {file} (Category: {category_name}) with encoding '{detected_encoding}'\")\n",
    "            success = True\n",
    "        except Exception:\n",
    "            pass  # Try alternative encodings and separators if this fails\n",
    "\n",
    "        # Try different encodings and separators if needed\n",
    "        if not success:\n",
    "            for encoding in common_encodings:\n",
    "                for separator in common_separators:\n",
    "                    try:\n",
    "                        df = pd.read_csv(file_path, encoding=encoding, sep=separator, engine='python')\n",
    "                        dataframes[category_name][file] = df\n",
    "                        print(f\"Successfully loaded {file} (Category: {category_name}) with encoding '{encoding}' and separator '{separator}'\")\n",
    "                        success = True\n",
    "                        break  # Stop trying if successful\n",
    "                    except Exception:\n",
    "                        continue  # Try next separator\n",
    "\n",
    "                if success:\n",
    "                    break  # Stop trying other encodings\n",
    "\n",
    "        # If all methods fail, print an error message\n",
    "        if not success:\n",
    "            print(f\"Unable to read {file} in category '{category_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Vertical Stack of Files/DataFrames According to Their Category\n",
    "\n",
    "In this step, I want to combine all dataframes that represent one category but are separated by year (e.g., vehicules_2011.csv, vehicules_2012.csv, vehicules_2013.csv, vehicules_2014.csv, etc.).\n",
    "\n",
    "Here is a list of problems that need to be addressed to ensure consistency when stacking vertically:\n",
    "\n",
    "- Ensure that column names are the same in every file (this includes whitespace and capitalization and columns with no names). \n",
    "  normalized_columns.replace('', 'unnamed') deals with empty column names \n",
    "  df.columns = df.columns.str.strip().str.lower() deals with whitespace and capitalization.\n",
    "\n",
    "- Ensure that the columns have the same data type (int, str, float, etc.). This is not necessary when using pd.concat(). Columns with different types are upcasted automatically, and you can define the type later. Upcasting hierarchy: bool → int → float → str → object.\n",
    "Not so true, better check for consistent data types, its a first good indicator if values are consistent within in the columns and dataframes you want to concat/merge\n",
    "\n",
    "- if you know the columns should be integer or float but apearing to be object or string its worth it to investigate if there are special characters or letters in the values\n",
    "\n",
    "- if they should be integer vut are float, they may have decimal numbers\n",
    "\n",
    "- Ensure that the columns have the same order/alignment. This is not necessary when using pd.concat(), as alignment happens automatically.\n",
    "\n",
    "- Check for duplicates after stacking.\n",
    "\n",
    "- The number of columns should be equal in every dataframe. When using pd.concat(), columns that exist in dataframes will still be included, but missing values (NaN) will be filled in where data is absent.\n",
    "\n",
    "<b>Summary: When using pd.concat(), the most important step to take when vertical stacking dataframes is ensuring that the corresponding column names in all frames are identical.</b>\n",
    "\n",
    "The following code removes whitespace and capitalization and compares the count of dataframes in a category with the occurences of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: v Total count 9 | Column: 'id_vehicule' | count is: 5 <- mismatch\n",
      "Category: v Total count 9 | Column: 'motor' | count is: 5 <- mismatch\n",
      "-----\n",
      "Category: u Total count 9 | Column: 'secu' | count is: 4 <- mismatch\n",
      "Category: u Total count 9 | Column: 'id_vehicule' | count is: 5 <- mismatch\n",
      "Category: u Total count 9 | Column: 'secu1' | count is: 5 <- mismatch\n",
      "Category: u Total count 9 | Column: 'secu2' | count is: 5 <- mismatch\n",
      "Category: u Total count 9 | Column: 'secu3' | count is: 5 <- mismatch\n",
      "Category: u Total count 9 | Column: 'id_usager' | count is: 3 <- mismatch\n",
      "-----\n",
      "Category: l Total count 9 | Column: 'env1' | count is: 4 <- mismatch\n",
      "Category: l Total count 9 | Column: 'vma' | count is: 5 <- mismatch\n",
      "-----\n",
      "Category: c Total count 9 | Column: 'num_acc' | count is: 8 <- mismatch\n",
      "Category: c Total count 9 | Column: 'gps' | count is: 4 <- mismatch\n",
      "Category: c Total count 9 | Column: 'accident_id' | count is: 1 <- mismatch\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each category, excluding \"not_chosen\"\n",
    "for category_name, category_files in dataframes.items():\n",
    "    if category_name == \"not_chosen\" or category_name == \"y\":\n",
    "        continue  # Skip files that were not categorized\n",
    "\n",
    "    column_counter = Counter()  # Counter to track column occurrences\n",
    "\n",
    "    # Process each file in the category\n",
    "    for file, df in category_files.items():\n",
    "        if df is not None:\n",
    "            # Normalize the column names by stripping whitespace and converting to lowercase\n",
    "            df.columns = df.columns.str.strip().str.lower()\n",
    "\n",
    "            # Replace empty column names with a default name (e.g., 'unnamed')\n",
    "            df.columns = [col if col != '' else 'unnamed' for col in df.columns]\n",
    "\n",
    "            # Count occurrences of each normalized column name\n",
    "            for column in df.columns:\n",
    "                column_counter[column] += 1\n",
    "\n",
    "    # Check for mismatches (where count != number of files)\n",
    "    num_files = len(category_files)\n",
    "    for column, count in column_counter.items():\n",
    "        if count != num_files:\n",
    "            print(f\"Category: {category_name} Total count {num_files} | Column: '{column}' | count is: {count} <- mismatch\")\n",
    "\n",
    "    # Print separator after each category to make the output clearer\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation of mismatches where the occurence of column names is not equal to the number of dataframes in a category\n",
    "\n",
    "```Category: v | Column: 'id_vehicule' | Occurrences: 5 <- mismatch\n",
    "Category: v | Column: 'motor' | Occurrences: 5 <- mismatch\n",
    "\n",
    "Category: u | Column: 'secu' | Occurrences: 14 <- mismatch\n",
    "Category: u | Column: 'id_vehicule' | Occurrences: 5 <- mismatch\n",
    "Category: u | Column: 'secu1' | Occurrences: 5 <- mismatch\n",
    "Category: u | Column: 'secu2' | Occurrences: 5 <- mismatch\n",
    "Category: u | Column: 'secu3' | Occurrences: 5 <- mismatch\n",
    "Category: u | Column: 'id_usager' | Occurrences: 3 <- mismatch\n",
    "\n",
    "Category: l | Column: 'env1' | Occurrences: 14 <- mismatch\n",
    "Category: l | Column: 'vma' | Occurrences: 5 <- mismatch\n",
    "\n",
    "Category: c | Column: 'num_acc' | Occurrences: 18 <- mismatch\n",
    "Category: c | Column: 'gps' | Occurrences: 14 <- mismatch\n",
    "Category: c | Column: 'accident_id' | Occurrences: 1 <- mismatch\n",
    "```\n",
    "\n",
    "To gain more knowlege i read to the documentation of the dataset: \"In 2019, the accident database was updated\"\n",
    "Regarding the columns names with the occurences of 5, the variables were introduced 2019 so 5 makes sence when having data up to the year 2023.\n",
    "In reverse columns names with the occurences of 14 pointing towards variables which were excluded from 2019 on.\n",
    "\n",
    "\n",
    "```\n",
    "id_usager: Unique identifier for each user (including pedestrians linked to the vehicle that hit them) – Numeric code.\n",
    "The variable seems to be introduced in 2021\n",
    "\n",
    "In the following code the columns with wrong names get renamed:\n",
    "- accident_id need to be renamed in num_acc\n",
    "- 'type accident - libellé (old)' to 'type accident - libellé'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed columns in file: carcteristiques-2022.csv in category 'c'.\n"
     ]
    }
   ],
   "source": [
    "#Renaming accident_id to num_acc \n",
    "# Iterate through the files in categories \"v\", \"u\", \"l\", \"c\", \"y\"\n",
    "for category_name in [\"v\", \"u\", \"l\", \"c\", \"y\"]:\n",
    "    for file, df in dataframes[category_name].items():\n",
    "        # Check if 'accident_id' column is present and rename it\n",
    "        if 'accident_id' in df.columns or 'type accident - libellé (old)' in df.columns:\n",
    "            df.rename(columns={\n",
    "                'accident_id':'num_acc',\n",
    "                'type accident - libellé (old)':'type accident - libellé'\n",
    "                }, inplace=True)\n",
    "            print(f\"Renamed columns in file: {file} in category '{category_name}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for consistent data types of columns in the same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking category: v\n",
      "  Column 'senc' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 0.0, 3.0, -1.0 | Low count (random 5): -1.0\n",
      "  Column 'occutc' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'float'> | Top 5: 0.0, 1.0, 2.0, 3.0, 10.0 | Low count (random 5): 250.0, 78.0, 128.0, 210.0, 77.0\n",
      "  Column 'obs' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 0.0, 1.0, 13.0, 2.0, 4.0 | Low count (random 5): -1.0\n",
      "  Column 'obsm' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 2.0, 0.0, 1.0, 9.0, 6.0 | Low count (random 5): -1.0\n",
      "  Column 'choc' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 3.0, 2.0, 4.0, 8.0 | Low count (random 5): -1.0\n",
      "  Column 'manv' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 15.0, 0.0, 13.0 | Low count (random 5): -1.0\n",
      "\n",
      "Checking category: u\n",
      "  Column 'place' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 10.0, 3.0, 4.0 | Low count (random 5): -1.0\n",
      "  Column 'trajet' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 5.0, 0.0, 1.0, 4.0, 9.0 | Low count (random 5): -1.0\n",
      "  Column 'locp' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 0.0, -1.0, 3.0, 2.0, 4.0 | Low count (random 5): 7.0\n",
      "  Column 'actp' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'str'> | Top 5: 0.0, 0,  -1, 3, 3.0 | Low count (random 5): 8\n",
      "  Column 'etatp' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: -1.0, 0.0, 1.0, 2.0, 3.0 | Low count (random 5): 3.0\n",
      "  Column 'an_nais' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'float'> | Top 5: 1996.0, 1995.0, 1997.0, 1998.0, 1994.0 | Low count (random 5): 1912.0\n",
      "\n",
      "Checking category: l\n",
      "  Column 'voie' → Mixed types: {<class 'float'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 0, 0.0, 1, 7, 86 | Low count (random 5): CHEMIN DE CROUY, Avenue Saint Pierre ancienne RD 84, COTEAUX (ALLEE DES) 1 - 33 TER, PARACLET (RUE DU), STAND (AVENUE)\n",
      "  Column 'v1' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'float'> | Top 5: 0.0, -1.0, 2.0, 3.0 | Low count (random 5): 3.0\n",
      "  Column 'v2' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'float'> | Top 5: D, A, N, E, B | Low count (random 5): v, .,  D, 1A, k\n",
      "  Column 'circ' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 2.0, 1.0, 3.0, -1.0, 0.0 | Low count (random 5): 4.0\n",
      "  Column 'nbv' → Mixed types: {<class 'int'>, <class 'str'>, <class 'float'>} | Most common: <class 'float'> | Top 5: 2.0, 2, 1.0, 4.0, 3.0 | Low count (random 5): #ERREUR\n",
      "  Column 'pr' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'str'> | Top 5: 0, (1),  -1, 0.0, 1 | Low count (random 5): 3500.0, 1521.0, 468.0, 920, 465\n",
      "  Column 'pr1' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'str'> | Top 5: 0, (1), 0.0,  -1, 500 | Low count (random 5): 2Â 600, 1720, 1317, 3116.0, 1068.0\n",
      "  Column 'vosp' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 0.0, 1.0, 3.0, 2.0, -1.0 | Low count (random 5): -1.0\n",
      "  Column 'prof' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 0.0, 3.0, 4.0 | Low count (random 5): -1.0\n",
      "  Column 'plan' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 3.0, 0.0, 4.0 | Low count (random 5): -1.0\n",
      "  Column 'lartpc' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'float'> | Top 5: 0.0, 15.0, 10.0, 20.0, 30.0 | Low count (random 5): 1,2, 760.0, 807.0, 2,7, 177.0\n",
      "  Column 'larrout' → Mixed types: {<class 'str'>, <class 'float'>} | Most common: <class 'float'> | Top 5:  -1, 0.0, 60.0, 70.0, 7 | Low count (random 5): 5,25, 3,25, 950.0, 1,4, 930.0\n",
      "  Column 'surf' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 0.0, 9.0, 7.0 | Low count (random 5): -1.0\n",
      "  Column 'infra' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 0.0, 5.0, 9.0, 2.0, 3.0 | Low count (random 5): 7.0\n",
      "  Column 'situ' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 3.0, 0.0, 4.0, 8.0 | Low count (random 5): -1.0\n",
      "\n",
      "Checking category: c\n",
      "  Column 'hrmn' → Mixed types: {<class 'int'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 18:00, 1800, 17:00, 1700, 18:30 | Low count (random 5): 341, 516, 04:39, 246, 441\n",
      "  Column 'dep' → Mixed types: {<class 'int'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 75, 750, 130, 93, 13 | Low count (random 5): 975\n",
      "  Column 'com' → Mixed types: {<class 'int'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 55, 116, 75116, 117, 7 | Low count (random 5): 53240, 70216, 70446, 38147, 81022\n",
      "  Column 'atm' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 1.0, 2.0, 8.0, 3.0, 7.0 | Low count (random 5): -1.0\n",
      "  Column 'col' → Mixed types: {<class 'int'>, <class 'float'>} | Most common: <class 'int'> | Top 5: 6.0, 3.0, 2.0, 1.0, 7.0 | Low count (random 5): -1.0\n",
      "  Column 'adr' → Mixed types: {<class 'float'>, <class 'str'>} | Most common: <class 'str'> | Top 5: AUTOROUTE A86, A4, AUTOROUTE A1, AUTOROUTE A3, A13 | Low count (random 5): Lieu dit Le Schnellenbuh, 138, CASANOVA DANIELLE N, A71-PK148+700, 4 QUAI DU GL DE GAULLE, RD111/ALLEE PASTEUR\n",
      "  Column 'lat' → Mixed types: {<class 'float'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 0.0, 4800000.0, 4889276.0, 4886000.0, 4885850.0 | Low count (random 5): 45,0738520, 42,7006747133, 48,9131070, 49,45399000, 44,7739100\n",
      "  Column 'long' → Mixed types: {<class 'float'>, <class 'str'>} | Most common: <class 'str'> | Top 5: 0.0, 228547.0, 220000.0, 6000000.0, 228759.0 | Low count (random 5):  -1,7760237, 5,3449050, 6,57701800, -116115.0, 5,1563160000\n",
      "  Column 'gps' → Mixed types: {<class 'float'>, <class 'str'>} | Most common: <class 'str'> | Top 5: M, A, R, G, Y | Low count (random 5): Y\n",
      "\n",
      "Checking category: y\n",
      "\n",
      "No mixed data types found in category: y\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to find mixed data type columns and display relevant details\n",
    "def find_mixed_dtype_columns(category, df_dict):\n",
    "    mixed_columns = {}\n",
    "\n",
    "    # Aggregate data for each column across all DataFrames in the category\n",
    "    for df in df_dict.values():\n",
    "        for col in df.columns:\n",
    "            if col not in mixed_columns:\n",
    "                mixed_columns[col] = []\n",
    "            mixed_columns[col].extend(df[col])\n",
    "\n",
    "    # Process each column\n",
    "    found_mixed = False\n",
    "    for col, values in mixed_columns.items():\n",
    "        unique_types = set(map(type, values))\n",
    "\n",
    "        if len(unique_types) > 1:  # More than one unique data type\n",
    "            found_mixed = True\n",
    "            most_common_dtype = Counter(map(type, values)).most_common(1)[0][0]\n",
    "            value_counts = pd.Series(values).value_counts()\n",
    "\n",
    "            top_5 = value_counts.head(5).index.tolist()\n",
    "            low_count_values = value_counts[value_counts == value_counts.min()]\n",
    "\n",
    "            if len(low_count_values) > 5:\n",
    "                low_count_values = low_count_values.sample(5)\n",
    "\n",
    "            low_count_values = low_count_values.index.tolist()\n",
    "\n",
    "            print(f\"  Column '{col}' → Mixed types: {unique_types} | Most common: {most_common_dtype} | \"\n",
    "                  f\"Top 5: {', '.join(map(str, top_5))} | \"\n",
    "                  f\"Low count (random 5): {', '.join(map(str, low_count_values))}\")\n",
    "\n",
    "    if not found_mixed:\n",
    "        print(f\"\\nNo mixed data types found in category: {category}\")\n",
    "\n",
    "# Iterate over each category, excluding \"not_chosen\" and \"y\"\n",
    "for category, dfs in dataframes.items():\n",
    "    if category == \"not_chosen\":\n",
    "        continue\n",
    "    print(f\"\\nChecking category: {category}\")\n",
    "    find_mixed_dtype_columns(category, dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing modifications of the upcast script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Upcasting columns in category: v\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'senc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'occutc' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obs' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'obsm' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'choc' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'manv' upcasted to float64\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "\n",
      "Upcasting columns in category: u\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'place' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'trajet' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'locp' upcasted to float64\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'actp' upcasted to string in all DataFrames\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'etatp' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'an_nais' upcasted to float64\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'num_veh' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_vehicule' upcasted to string in all DataFrames\n",
      "Column 'id_usager' upcasted to string in all DataFrames\n",
      "Column 'id_usager' upcasted to string in all DataFrames\n",
      "Column 'id_usager' upcasted to string in all DataFrames\n",
      "\n",
      "Upcasting columns in category: l\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'voie' upcasted to string in all DataFrames\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v1' upcasted to float64\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'v2' upcasted to string in all DataFrames\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'circ' upcasted to float64\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'nbv' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'pr1' upcasted to string in all DataFrames\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'vosp' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'prof' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'plan' upcasted to float64\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'lartpc' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'larrout' upcasted to string in all DataFrames\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'surf' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'infra' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "Column 'situ' upcasted to float64\n",
      "\n",
      "Upcasting columns in category: c\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'hrmn' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'dep' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'com' upcasted to string in all DataFrames\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'atm' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'col' upcasted to float64\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'adr' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'lat' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'long' upcasted to string in all DataFrames\n",
      "Column 'gps' upcasted to string in all DataFrames\n",
      "Column 'gps' upcasted to string in all DataFrames\n",
      "Column 'gps' upcasted to string in all DataFrames\n",
      "Column 'gps' upcasted to string in all DataFrames\n",
      "\n",
      "Upcasting columns in category: y\n"
     ]
    }
   ],
   "source": [
    "def find_and_upcast_mixed_dtype_columns(category, df_dict):\n",
    "    mixed_columns = {}\n",
    "    columns_with_strings = set()  # Track columns that contain strings\n",
    "\n",
    "    # Aggregate data for each column across all DataFrames in the category\n",
    "    for df in df_dict.values():\n",
    "        for col in df.columns:\n",
    "            if col not in mixed_columns:\n",
    "                mixed_columns[col] = []\n",
    "            mixed_columns[col].extend(df[col])  \n",
    "\n",
    "    # Identify columns that contain strings\n",
    "    for col, values in mixed_columns.items():\n",
    "        unique_types = set(map(type, values))\n",
    "        \n",
    "        # If a column has any string, mark it for upcasting\n",
    "        if str in unique_types or object in unique_types:\n",
    "            columns_with_strings.add(col)\n",
    "\n",
    "    # Convert columns as needed\n",
    "    for col, values in mixed_columns.items():\n",
    "        unique_types = set(map(type, values))\n",
    "\n",
    "        # If this column is in the \"string list\", upcast all instances to string\n",
    "        if col in columns_with_strings:\n",
    "            for df in df_dict.values():\n",
    "                if col in df.columns:\n",
    "                    df[col] = df[col].astype(str)\n",
    "                    print(f\"Column '{col}' upcasted to string in all DataFrames\")\n",
    "\n",
    "        # If mixed int and float, convert to float64 (only if it wasn't marked for string)\n",
    "        elif {int, float}.issubset(unique_types):\n",
    "            for df in df_dict.values():\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype('float64')\n",
    "                    print(f\"Column '{col}' upcasted to float64\")\n",
    "\n",
    "# Iterate over each category, excluding \"not_chosen\"\n",
    "for category, dfs in dataframes.items():\n",
    "    if category == \"not_chosen\":\n",
    "        continue\n",
    "    print(f\"\\nUpcasting columns in category: {category}\")\n",
    "    find_and_upcast_mixed_dtype_columns(category, dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do check if foat64 c variables can be downcasted to integer for better performance \n",
    "1. decimal parts who are 0 and in this case pass the column name to a dtype_conversion dictionary\n",
    "2. if there is a decimal part, show me the most common uniques and the number with decimal part to decide if we keep float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerunning mixed types test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking category: v\n",
      "\n",
      "No mixed data types found in category: v\n",
      "\n",
      "Checking category: u\n",
      "\n",
      "No mixed data types found in category: u\n",
      "\n",
      "Checking category: l\n",
      "\n",
      "No mixed data types found in category: l\n",
      "\n",
      "Checking category: c\n",
      "\n",
      "No mixed data types found in category: c\n",
      "\n",
      "Checking category: y\n",
      "\n",
      "No mixed data types found in category: y\n"
     ]
    }
   ],
   "source": [
    "# Function to find mixed data type columns and display relevant details\n",
    "def find_mixed_dtype_columns(category, df_dict):\n",
    "    mixed_columns = {}\n",
    "\n",
    "    # Aggregate data for each column across all DataFrames in the category\n",
    "    for df in df_dict.values():\n",
    "        for col in df.columns:\n",
    "            if col not in mixed_columns:\n",
    "                mixed_columns[col] = []\n",
    "            mixed_columns[col].extend(df[col])\n",
    "\n",
    "    # Process each column\n",
    "    found_mixed = False\n",
    "    for col, values in mixed_columns.items():\n",
    "        unique_types = set(map(type, values))\n",
    "\n",
    "        if len(unique_types) > 1:  # More than one unique data type\n",
    "            found_mixed = True\n",
    "            most_common_dtype = Counter(map(type, values)).most_common(1)[0][0]\n",
    "            value_counts = pd.Series(values).value_counts()\n",
    "\n",
    "            top_5 = value_counts.head(5).index.tolist()\n",
    "            low_count_values = value_counts[value_counts == value_counts.min()]\n",
    "\n",
    "            if len(low_count_values) > 5:\n",
    "                low_count_values = low_count_values.sample(5)\n",
    "\n",
    "            low_count_values = low_count_values.index.tolist()\n",
    "\n",
    "            print(f\"  Column '{col}' → Mixed types: {unique_types} | Most common: {most_common_dtype} | \"\n",
    "                  f\"Top 5: {', '.join(map(str, top_5))} | \"\n",
    "                  f\"Low count (random 5): {', '.join(map(str, low_count_values))}\")\n",
    "\n",
    "    if not found_mixed:\n",
    "        print(f\"\\nNo mixed data types found in category: {category}\")\n",
    "\n",
    "# Iterate over each category, excluding \"not_chosen\" and \"y\"\n",
    "for category, dfs in dataframes.items():\n",
    "    if category == \"not_chosen\":\n",
    "        continue\n",
    "    print(f\"\\nChecking category: {category}\")\n",
    "    find_mixed_dtype_columns(category, dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time for the vertical merges in every category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: v - Merged DataFrame shape: (871293, 11)\n",
      "Files merged for category 'v': vehicules-2017.csv, vehicules-2018.csv, vehicules-2019.csv, vehicules-2020.csv, vehicules-2021.csv, vehicules-2022.csv, vehicules-2023.csv, vehicules_2015.csv, vehicules_2016.csv\n",
      "-----\n",
      "Category: u - Merged DataFrame shape: (1149961, 17)\n",
      "Files merged for category 'u': usagers-2017.csv, usagers-2018.csv, usagers-2019.csv, usagers-2020.csv, usagers-2021.csv, usagers-2022.csv, usagers-2023.csv, usagers_2015.csv, usagers_2016.csv\n",
      "-----\n",
      "Category: l - Merged DataFrame shape: (525834, 19)\n",
      "Files merged for category 'l': lieux-2017.csv, lieux-2018.csv, lieux-2019.csv, lieux-2020.csv, lieux-2021.csv, lieux-2022.csv, lieux-2023.csv, lieux_2015.csv, lieux_2016.csv\n",
      "-----\n",
      "Category: c - Merged DataFrame shape: (509796, 16)\n",
      "Files merged for category 'c': caract-2023.csv, caracteristiques-2017.csv, caracteristiques-2018.csv, caracteristiques-2019.csv, caracteristiques-2020.csv, caracteristiques_2015.csv, caracteristiques_2016.csv, carcteristiques-2021.csv, carcteristiques-2022.csv\n",
      "-----\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each category, excluding \"not_chosen\"\n",
    "for category_name in [\"v\", \"u\", \"l\", \"c\", \"y\"]:\n",
    "    dataframes_to_merge = []  # List to hold DataFrames for each category\n",
    "    merged_files = []  # List to store file names that were merged\n",
    "\n",
    "    for file, df in dataframes[category_name].items():\n",
    "        if df is not None:\n",
    "            # Add the DataFrame to the list\n",
    "            dataframes_to_merge.append(df)\n",
    "            # Store the file name\n",
    "            merged_files.append(file)\n",
    "\n",
    "    # Check if there are DataFrames to merge\n",
    "    if dataframes_to_merge:\n",
    "        # Concatenate all DataFrames in the list vertically (along rows)\n",
    "        merged_df = pd.concat(dataframes_to_merge, ignore_index=True)\n",
    "        \n",
    "        # Optionally, save the merged DataFrame to a new dictionary\n",
    "        dataframes[category_name][\"merged\"] = merged_df\n",
    "        \n",
    "        # Print the shape of the merged DataFrame for the category\n",
    "        print(f\"Category: {category_name} - Merged DataFrame shape: {merged_df.shape}\")\n",
    "        print(f\"Files merged for category '{category_name}': {', '.join(merged_files)}\")\n",
    "\n",
    "    # Print separator after each category to make the output clearer\n",
    "    print(\"-----\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: v - No duplicates found.\n",
      "Category: u - Found 796 duplicate rows:\n",
      "              num_acc  place  catu  grav  sexe  trajet  secu  locp actp  \\\n",
      "1600     201700000700    5.0     2     1     1     5.0  13.0   0.0  0.0   \n",
      "3387     201700001487    7.0     2     1     2     2.0  13.0   0.0  0.0   \n",
      "3390     201700001487    7.0     2     3     2     2.0  11.0   0.0  0.0   \n",
      "3393     201700001487    8.0     2     1     2     2.0  13.0   0.0  0.0   \n",
      "3395     201700001487    8.0     2     1     2     2.0  13.0   0.0  0.0   \n",
      "...               ...    ...   ...   ...   ...     ...   ...   ...  ...   \n",
      "1145627  201600057549    5.0     2     4     1     0.0  11.0   0.0  0.0   \n",
      "1145628  201600057549    5.0     2     4     2     0.0  11.0   0.0  0.0   \n",
      "1145629  201600057549    5.0     2     4     1     0.0  11.0   0.0  0.0   \n",
      "1146246  201600057814    2.0     2     4     1     0.0  12.0   0.0  0.0   \n",
      "1149705  201600059294    NaN     3     4     1     5.0   NaN   1.0  3.0   \n",
      "\n",
      "         etatp  an_nais num_veh id_vehicule  secu1  secu2  secu3 id_usager  \n",
      "1600       0.0   2000.0     B01         NaN    NaN    NaN    NaN       NaN  \n",
      "3387       0.0   2002.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "3390       0.0   2004.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "3393       0.0   2002.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "3395       0.0   2003.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "...        ...      ...     ...         ...    ...    ...    ...       ...  \n",
      "1145627    0.0   2001.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "1145628    0.0   2001.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "1145629    0.0   2001.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "1146246    0.0   2002.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "1149705    2.0   2005.0     A01         NaN    NaN    NaN    NaN       NaN  \n",
      "\n",
      "[796 rows x 17 columns]\n",
      "Category: l - No duplicates found.\n",
      "Category: c - No duplicates found.\n",
      "Category: y - No merged DataFrame found.\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in each merged DataFrame\n",
    "for category_name in [\"v\", \"u\", \"l\", \"c\", \"y\"]:\n",
    "    if \"merged\" in dataframes[category_name]:  # Ensure merged data exists\n",
    "        merged_df = dataframes[category_name][\"merged\"]\n",
    "\n",
    "        # Find duplicate rows\n",
    "        duplicates = merged_df[merged_df.duplicated()]\n",
    "        \n",
    "        if not duplicates.empty:\n",
    "            print(f\"Category: {category_name} - Found {len(duplicates)} duplicate rows:\")\n",
    "            print(duplicates)  # Print duplicate rows\n",
    "        else:\n",
    "            print(f\"Category: {category_name} - No duplicates found.\")\n",
    "    else:\n",
    "        print(f\"Category: {category_name} - No merged DataFrame found.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: v - 0 duplicate rows removed.\n",
      "New shape after dropping duplicates: (871293, 11)\n",
      "Category: u - 796 duplicate rows removed.\n",
      "New shape after dropping duplicates: (1149165, 17)\n",
      "Category: l - 0 duplicate rows removed.\n",
      "New shape after dropping duplicates: (525834, 19)\n",
      "Category: c - 0 duplicate rows removed.\n",
      "New shape after dropping duplicates: (509796, 16)\n",
      "Category: y - No merged DataFrame found.\n"
     ]
    }
   ],
   "source": [
    "#Iterate through each category and drop duplicates in the merged DataFrame\n",
    "for category_name in [\"v\", \"u\", \"l\", \"c\", \"y\"]:\n",
    "    if \"merged\" in dataframes[category_name]:  # Ensure merged data exists\n",
    "        merged_df = dataframes[category_name][\"merged\"]\n",
    "        \n",
    "        # Drop duplicates and update the DataFrame\n",
    "        cleaned_df = merged_df.drop_duplicates()\n",
    "\n",
    "        # Store the cleaned DataFrame back in the dictionary\n",
    "        dataframes[category_name][\"merged\"] = cleaned_df\n",
    "\n",
    "        # Print the number of duplicates removed\n",
    "        print(f\"Category: {category_name} - {len(merged_df) - len(cleaned_df)} duplicate rows removed.\")\n",
    "        print(f\"New shape after dropping duplicates: {cleaned_df.shape}\")\n",
    "    else:\n",
    "        print(f\"Category: {category_name} - No merged DataFrame found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the vertical stacked dataframes as csv-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category: v - Merged DataFrame saved to C:\\DS_Project_RoadAcc\\merged_data_2015-2023\\v_2015-2023.csv\n",
      "Category: u - Merged DataFrame saved to C:\\DS_Project_RoadAcc\\merged_data_2015-2023\\u_2015-2023.csv\n",
      "Category: l - Merged DataFrame saved to C:\\DS_Project_RoadAcc\\merged_data_2015-2023\\l_2015-2023.csv\n",
      "Category: c - Merged DataFrame saved to C:\\DS_Project_RoadAcc\\merged_data_2015-2023\\c_2015-2023.csv\n",
      "Category: y - No merged DataFrame to save.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the output folder path\n",
    "output_folder = r\"C:\\DS_Project_RoadAcc\\merged_data_2015-2023\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Iterate through each category and save the merged DataFrame\n",
    "for category_name in [\"v\", \"u\", \"l\", \"c\", \"y\"]:\n",
    "    if \"merged\" in dataframes[category_name]:  # Ensure merged data exists\n",
    "        merged_df = dataframes[category_name][\"merged\"]\n",
    "        \n",
    "        # Define the file path\n",
    "        file_path = os.path.join(output_folder, f\"{category_name}_2015-2023.csv\")\n",
    "\n",
    "        # Save the DataFrame as a CSV file\n",
    "        merged_df.to_csv(file_path, index=False)\n",
    "\n",
    "        print(f\"Category: {category_name} - Merged DataFrame saved to {file_path}\")\n",
    "    else:\n",
    "        print(f\"Category: {category_name} - No merged DataFrame to save.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
